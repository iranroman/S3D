@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}

@article{kim2018flowavenet,
  title={FloWaveNet: A generative flow for raw audio},
  author={Kim, Sungwon and Lee, Sang-Gil and Song, Jongyoon and Kim, Jaehyeon and Yoon, Sungroh},
  journal={arXiv preprint arXiv:1811.02155},
  year={2018}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@inproceedings{yang2020telling,
  title={Telling left from right: Learning spatial correspondence of sight and sound},
  author={Yang, Karren and Russell, Bryan and Salamon, Justin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9932--9941},
  year={2020}
}

@article{stoller2018wave,
  title={Wave-u-net: A multi-scale neural network for end-to-end audio source separation},
  author={Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
  journal={arXiv preprint arXiv:1806.03185},
  year={2018}
}

@inproceedings{gao20192,
  title={2.5 d visual sound},
  author={Gao, Ruohan and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={324--333},
  year={2019}
}

@inproceedings{kurz2015comparison,
  title={Comparison of first-order Ambisonics microphone arrays},
  author={Kurz, Eric and Pfahler, Felix and Frank, Matthias},
  booktitle={3rd International Conference on Spatial Audio, ICSA},
  year={2015}
}

@inproceedings{bates2017comparing,
  title={Comparing Ambisonic Microphonesâ€”Part 2},
  author={Bates, Enda and Dooney, Sean and Gorzel, Marcin and O'Dwyer, Hugh and Ferguson, Luke and Boland, Francis M},
  booktitle={Audio Engineering Society Convention 142},
  year={2017},
  organization={Audio Engineering Society}
}

@inproceedings{lopez2019sphear,
  title={The SpHEAR project update: Refining the OctaSpHEAR, a 2nd order ambisonics microphone},
  author={Lopez-Lezcano, Fernando},
  booktitle={EAA Spatial Audio Signal Processing Symposium},
  pages={103--108},
  year={2019}
}

@inproceedings{simonovsky2017dynamic,
  title={Dynamic edge-conditioned filters in convolutional neural networks on graphs},
  author={Simonovsky, Martin and Komodakis, Nikos},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3693--3702},
  year={2017}
}

@inproceedings{xiong2015conditional,
  title={Conditional convolutional neural network for modality-aware face recognition},
  author={Xiong, Chao and Zhao, Xiaowei and Tang, Danhang and Jayashree, Karlekar and Yan, Shuicheng and Kim, Tae-Kyun},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3667--3675},
  year={2015}
}

@inproceedings{Shimada2021,
  Author = "Shimada, Kazuki and Koyama, Yuichiro and Takahashi, Naoya and Takahashi, Shusuke and Mitsufuji, Yuki",
  title = "ACCDOA: Activity-Coupled Cartesian Direction of Arrival Representation for Sound Event Localization and Detection",
  abstract = "Neural-network (NN)-based methods show high performance in sound event localization and detection (SELD). Conventional NN-based methods use two branches for a sound event detection (SED) target and a direction-of-arrival (DOA) target. The two-branch representation with a single network has to decide how to balance the two objectives during optimization. Using two networks dedicated to each task increases system complexity and network size. To address these problems, we propose an activity-coupled Cartesian DOA (ACCDOA) representation, which assigns a sound event activity to the length of a corresponding Cartesian DOA vector. The ACCDOA representation enables us to solve a SELD task with a single target and has two advantages: avoiding the necessity of balancing the objectives and model size increase. In experimental evaluations with the DCASE 2020 Task 3 dataset, the ACCDOA representation outperformed the two-branch representation in SELD metrics with a smaller network size. The ACCDOA-based SELD system also performed better than state-of-the-art SELD systems in terms of localization and location-dependent detection.",
  month = "June",
  year = "2021",
  address = "Toronto, Ontario, Canada",
  booktitle = "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
}
