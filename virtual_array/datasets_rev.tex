\documentclass[14pt, legalpaper]{extarticle} 
\usepackage{authblk, helvet, amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry, hyperref, lscape, makecell, longtable}
\usepackage[binary-units=true]{siunitx}
\renewcommand{\familydefault}{\sfdefault}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}


\title{A review of existings datasets with microphone array recordings}
\author{Iran R. Roman \thanks{roman@nyu.edu}}
\affil{Music and Audio Research Laboratory, New York University}
\date{}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}

\section{Introduction}

\subsection{Background}

\begin{itemize}

\item Localization and tracking allow intelligent agents to determine if objects are moving, in which direction, and how fast. 

\item From an evolutionary standpoint, object localization and tracking are essential for survival \cite{heffner2018evolution}.

\item Sound localization and tracking are fundamental problems of machine listening technologies.

\item Without these capabilities, {\it intelligent machines} cannot locate living beings and objects in their environment by the sounds they make. 

\end{itemize}

\subsection{Problem statement}

\begin{itemize}

\item Current machine listening models learn sound localization and tracking using a specific microphone array configuration. 

\item As a result, a unifying framework across models and microphone array configurations is  missing. 

\item To change a model's microphone array or simply add or remove channels in the data, the model architecture must also be changed and retrained, at least at the level of the input-processing units.

\end{itemize}

\subsection{Proposed solution}

\begin{itemize}

\item Microphone arrays come in numerous sizes and shapes \cite{kurz2015comparison, bates2017comparing, lopez2019sphear}. 

\item We should not think of individual microphone array configurations as mutually exclusive.

\item Instead, we can think of them as a subset of a virtual array with an infinite number of channels.

\item The virtual array is spherical in shape, and contains microphones at all positions and facing all possible directions of arrival.

\item For each microphone in an existing array, we know its signal captured, position, directionality, and frequency response. 

\item By combining information across microphone arrays, we can interpolate and approximate the virtual array.

\end{itemize}

\section{Scope of this review}

\begin{itemize}

\item This document will identify existing audio datasets collected with microphone arrays in different settings.

\item First, we describe the importance of microphone arrays for object localization and tracking.

\item Then, we list a reviews that list the technical specifications of commonly used microphone arrays.

\item Next, we present an overview of existing datasets with microphone arrays.

\end{itemize}

\section{Object localization and tracking with microphone arrays}

\subsection{Auditory object localization and tracking in animals}

\begin{itemize}

\item Intelligent organisms rely on sensory cues to interact with objects in their environment. 

\item Several mammalian species can localize and track objects based on the sounds they make.

\item To do this, many animals rely on their ears (two auditory inputs) and mechanisms of \cite{grothe2010mechanisms}:
	\begin{itemize}
	\item Monoaural cues (spectral analysis)
	\item Interaural time difference
	\item Interaural level difference
	\end{itemize}

\item Evolution also gave rise to other mechanisms for sound localization and tracking, including \cite{grothe2010mechanisms}: 
	\begin{itemize}
	\item Particle motion detection in fish 
	\item Processing of interfering patterns reaching the tympanum in frogs and birds
	\end{itemize}

\end{itemize}

\subsection{The need for microphone arrays}

\begin{itemize}

\item Many mammals are able to localize and track auditory objects in their enviroment using only two ears.

\item While a microphone array can have just two microphones, most have four or more. 

\item Why do we need microphone arrays to carry out the same task that many animals carry out with two ears?

\item Firstly, we want microphone arrays to robustly localize and track auditory objects in a wide array of environments, unlike animal species occupying an environmental niche.

\item Additionally, there two technical problems with binaural source localization in machines \cite{kim2015improved}:
	\begin{itemize}
	\item Diffraction of sound waves around the agent's head
	\item Front back ambiguity
	\end{itemize}

\item To overcome these issues, it is necessary to move the ears and head (like animals naturally do) and filter inputs with specific head-related transfer functions.

\item Alternatively, these technical problems can be solved using microphone arrays, which add spatial and auditory information. 

\item In machine listening, microphone arrays have been shown to be the optimal solution to carrying out sond source localization and tracking.

\item In general, the larger the number of microphones in an array, the better sound source localization results \cite{valin2007robust}.

\item Additionally, a microphone array allows for spatial subsampling.

\end{itemize}

\section{Commonly used microphone arrays}

\begin{itemize}

\item Hyunkook Lee recently published a review of microphone arrays \cite{lee2021multichannel}
	
\item He describes hardware and techniques for microphone arrays used in several of the datasets that will be described in this review. 

\item Note: some datasets described in this document use custom microphone arrays. In those cases, the original publication describing the dataset is the best source to understand the hardware and technical specifications of the microphone array.

\end{itemize}

\begin{landscape}
{\footnotesize
\begin{longtable}{|*{17}{l|}}
Dataset & \multicolumn{7}{l|}{Mic array(s)} & Signal(s) & \multicolumn{4}{l|}{Source(s)} & \multicolumn{2}{l|}{Env} & Hrs & Uses \\
\hline
& array & shape & ch & type & size & sampling & height & & type & dist (m) & height (m) & angles & room & RT60 & & \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/2599196}{DCASE t3} \\
2019 \\ \cite{adavanne2019multi}} &
EingeMike & sphere & 4ch & omni & \SI{0.001}{\cubic\metre} & \SI{48}{\kilo\hertz} & ? &
\makecell[tl]{\href{http://dcase.community/challenge2016/task-sound-event-detection-in-synthetic-audio}{DCASE} \\ 16 t2} & 
synthetic & \SI{1},\SI{2} & ? & 504 &
\makecell[tl]{corridor \\ cafeteria \\ lounge} & ? &
8 &
src pos \cite{kapka2019sound} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/4064792}{DCASE t3} \\
2020 \\ \cite{politis2020dataset}} &
EingeMike & sphere & 4ch & omni & \SI{0.001}{\cubic\metre} & \SI{24}{\kilo\hertz} & ? &
\makecell[tl]{\href{https://zenodo.org/record/2535878}{NIGENS} \\ \cite{trowitzsch2019nigens}} & 
synthetic & varies & varies & varies &
\makecell[tl]{classroom \\ auditorium} & ? &
13 &
src trk \cite{shimada2020sound, wang2020ustc, nguyen2020dcase} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/4568781}{DCASE t3} \\
2021 \\ \cite{politis2021tau}} &
EingeMike & sphere & 4ch & omni & \SI{0.001}{\cubic\metre} & \SI{24}{\kilo\hertz} & ? &
\makecell[tl]{\href{https://zenodo.org/record/2535878}{NIGENS} \\ \cite{trowitzsch2019nigens} \\ dir interf} & 
synthetic & varies & varies & varies &
\makecell[tl]{lounge \\ cafeteria \\ hallway \\ auditorium \\ classroom \\ gym} & ? &
13 &
src trk \cite{shimada2020sound, wang2020ustc, nguyen2020dcase} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/1209563}{Pyramic} \\
2018 \\ \cite{scheibler2018pyramic}} &
Pyramic & tetrhdr & 48ch & MEMS & \SI{0.02}{\cubic\metre} & \SI{48}{\kilo\hertz}, \SI{16}{\bit} & \SI{1.1}{\metre} &
\makecell[tl]{sweeps \\ noise \\ speech} & 
loudspk & \SI{4} & \SI{0.25},\SI{1.3},\SI{2.2} &
180 unifm &
anechoic & \SI{0}{\second}&
2.5 &
\makecell[tl]{DoA \cite{bezzam2017hardware}, BF \cite{bezzam2017hardware, simeoni2019deepwave}, \\ acous imag \cite{simeoni2019deepwave}, \\ mic calib \cite{baechler2020coordinate}} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/3477602}{MARCo} \\
2020 \\ \cite{lee3d}} &
\makecell[tl]{OCT-3D \cite{theile20123d} \\ 2L-Cube \\ Decca \\ PCMA-3D \\ Hamasaki \\ EigenMike} & 
\makecell[tl]{cuboid \\ cuboid \\ cuboid \\ plane \\ cuboid \\ sphere} &
\makecell[tl]{9ch \\ 9ch \\ 9ch \\ 9ch \\ 12ch \\ 32ch} & 
\makecell[tl]{crd \\ omni \\ omni \\ crd \\ crd+8 \\ omni} &
\makecell[tl]{\SI{1}{\cubic\metre} \\ \SI{1}{\cubic\metre} \\ \SI{4}{\cubic\metre} \\ \SI{1}{\square\metre} \\ \SI{4}{\cubic\metre} \\ \SI{0.001}{\cubic\metre}} &
\makecell[tl]{\SI{96}{\kilo\hertz}, \SI{24}{\bit} \\ \SI{96}{\kilo\hertz}, \SI{24}{\bit} \\ \SI{96}{\kilo\hertz}, \SI{24}{\bit} \\ \SI{96}{\kilo\hertz}, \SI{24}{\bit} \\ \SI{96}{\kilo\hertz}, \SI{24}{\bit} \\ \SI{48}{\kilo\hertz}, \SI{16}{\bit}} & 
\makecell[tl]{\SI{2.7}{\metre} \\ \SI{2.7}{\metre} \\ \SI{2.7}{\metre} \\ \SI{2.7}{\metre} \\ \SI{2.4}{\metre} \\ \SI{2.7}{\metre}} &
\makecell[tl]{live \\ music \\ \\ \\ \\ sweeps} & 
\makecell[tl]{str qrt \\ piano \\ organ \\ clarinet \\ voice 5 \\ loudspk} & 
\makecell[tl]{\SI{2.6}{} \\ \SI{3.4}{} \\ \SI{12}{} \\ \SI{2.6}{} \\ \SI{2.6}{} \\ \SI{3.5}{} } & 
\makecell[tl]{ \\ \\ \\ \\ \\ \SI{1.14}{} } &
\makecell[tl]{ \\ \\ \\ \\ \\ 13 frnt hlf} &
conc hall & \SI{2.1}{\second}&
11.0 &
psyacous \cite{lee2021multichannel} \\

\hline
\makecell[tl]{\href{https://www.iks.rwth-aachen.de/en/research/tools-downloads/databases/multi-channel-impulse-response-database/}{MIRD} \\
2014 \\ \cite{hadad2014multichannel}} &
MIRD & planar & 8ch & omni & \SI{0.5}{\metre} & \SI{48}{\kilo\hertz}, \SI{24}{\bit} & \SI{1}{\metre} &
sweep & loudspk & \SI{1}, \SI{2} & \SI{1} & 13 frnt hlf &
\makecell[tl]{conf 1 \\ conf 2 \\ conf 3} & \makecell[tl]{\SI{0.16}{\second} \\ \SI{0.36}{\second} \\ \SI{0.61}{\second}} &
0.1 &
\makecell[tl]{src pos \cite{bianco2021semi} \\ speech enh \cite{gannot2017consolidated}} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/1227121}{DEMAND} \\
2013 \\ \cite{thiemann2013demand}} &
DEMAND & grid & 16ch & cond & \SI{0.04}{\square\metre} & \SI{48}{\kilo\hertz}, \SI{16}{\bit} & \SI{1.4}{\metre} &
ambient & & & & &
\makecell[tl]{home \\ nature \\ office \\ public \\ street \\ transp} & &
1.5 &
\makecell[tl]{BF \cite{thiemann2013experimental} \\ BSS \cite{thiemann2013experimental, thiemann2013fast} \\ mic calib \cite{thiemann2014spatial} \\ backgrnd noise} \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/3630471}{LOCATA} \\ 
2020 \\ \cite{evers2020data}} &
\makecell[tl]{NAO \cite{tourbabin2014theoretical} \\ EigenMike \\ DICIT \cite{brutti2010woz} \\ hearing aids \\ mo-cap} & 
\makecell[tl]{sphere \\ sphere \\ planar \\ } &
\makecell[tl]{12ch \\ 32ch \\ 15ch \\ 4ch} & 
\makecell[tl]{omni \\ omni \\ omni \\ omni} &
\makecell[tl]{\SI{0.001}{\cubic\metre} \\ \SI{0.001}{\cubic\metre} \\ \SI{2.24}{\metre} \\} &
\makecell[tl]{\SI{48}{\kilo\hertz} \\ \SI{48}{\kilo\hertz} \\ \SI{48}{\kilo\hertz} \\ \SI{48}{\kilo\hertz}} & ? &
speech & 
\makecell[tl]{multpl \\ loudspk \\ \\ multpl \\ human} & varies & varies & varies &
laboratory & \SI{0.55}{\second} &
0.5 &
\makecell[tl]{src pos \cite{evers2020data} \\ src trk \cite{evers2020data} \\ DoA \cite{pak2018locata}} \\

\hline
\makecell[tl]{\href{http://dregon.inria.fr}{DREGON} \\ 
2018 \\ \cite{strauss2018dregon}} & 
\makecell[tl]{drone mic \\ mic array \\ mo-cap} & \makecell[tl]{cube \\ cube}  & \makecell[tl]{8ch \\ 8ch}& \makecell[tl]{omni \\ omni} & 
\makecell[tl]{\SI{0.001}{\cubic\metre} \\ \SI{0.001}{\cubic\metre}} & 
\makecell[tl]{\SI{44.1}{\kilo\hertz} \\ \SI{44.1}{\kilo\hertz}} & ? &
\makecell[tl]{noise \\ speech \\ sweep \\ motor \\ ambient} &
loudspk & varies & varies & varies &
carp room & \SI{0.15}{\second} &
1.0 &
\makecell[tl]{DoA \cite{qayyum2019direction} \\ src pos \cite{qayyum2020doanet, aldeiasemblance} } \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/1284156}{EigenScape} \\
2017 \\ \cite{green2017eigenscape}} & 
EigenMike & sphere  & 32ch & omni & 
\SI{0.001}{\cubic\metre} & 
\SI{48}{\kilo\hertz}, \SI{24}{\bit} & \SI{1.5}{\metre} &
ambient & & & & &
\makecell[tl]{beach \\ street \\ park \\ ped zone \\ store \\ train stn \\ woods} & ? &
10.7 &
\makecell[tl]{scene clss \cite{green2020environmental,green2019acoustic} \\ psyacous \cite{mckenzie2019interaural} } \\

\hline
\makecell[tl]{\href{https://zenodo.org/record/3386569}{ARTE} \\
2019 \\ \cite{weisser2019ambisonic}} & 
ARTE & sphere  & 62ch & omni & 
\SI{0.001}{\cubic\metre} & 
\SI{44.1}{\kilo\hertz}, \SI{32}{\bit} & \SI{1.5}{\metre} &
\makecell[tl]{sweep \\ ambient} & loudspk & \SI{1.3}{} & ? & \SI{0}{\degree} &
\makecell[tl]{party \\ liv room \\ cafeteria \\ office \\ train stn \\ cafe} & ? &
0.5 &
psyacous \cite{weisser2019complex}\\
\caption{Technical specifications of microphone array datasets. Each dataset name includes a hyperlink to the official dataset repository. A question mark in a cell denotes information that could not be found in the dataset's documentation}
\label{tab:t1}
\end{longtable}
}
\end{landscape}

\section{Brief description of existing datasets with microphone arrays}

\subsection{DCASE 2019 task 3 (Adavanne et al., 2019)}

\begin{itemize}

\item Signals convolved with room impulse responses, generating synthetic recordings of static sources with a tetrahedral array (subset of the 32-channel EigenMike) \cite{adavanne2019multi}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{DCASE 2020 task 3 (Politis et al., 2020)}

\begin{itemize}

\item Signals convolved with room impulse responses, generating synthetic recordings of moving sources with a tetrahedral array (subset of the 32-channel EigenMike) \cite{politis2020dataset}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{DCASE 2021 task 3 (Politis et al., 2021)}

\begin{itemize}

\item Signals convolved with room impulse responses, generating synthetic recordings of moving sources with a tetrahedral array (subset of the 32-channel EigenMike) \cite{politis2021tau}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{Pyramic (Scheibler, 2018)}

\begin{itemize}

\item Sine sweeps, noise, and speech samples, recorded with a 48-channel microphone array in an anechoic chamber \cite{scheibler2018pyramic}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{3D-MARCo (Lee and Johnson, 2019)}

\begin{itemize}

\item Musical performances and room impulse reponses, recorded with different 3D microphone arrays (71 channels total) in a large concert hall \cite{lee3d}. See table \ref{tab:t1} for details. A similar dataset of room impulse responses is also available \cite{lee2017microphone}.

\end{itemize}

\subsection{MIRD (Hadad et al., 2014)}

\begin{itemize}

\item Sine sweep recordings with an 8-channel microphone array in three different acoustic environments \cite{hadad2014multichannel}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{DEMAND (Thiemann et al., 2013)}

\begin{itemize}

\item Ambient noise recorded with a 16-channel microphone array in domestic, nature, and office environments \cite{thiemann2013demand}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{LOCATA (Evers et al., 2020)}

\begin{itemize}

\item Moving speech sources, simultaneously recorded with different microphone arrays (over 60-channels in total) in a laboratory \cite{evers2020data}. Motion capture data included. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{DREGON (Strauss et al., 2018)}

\begin{itemize}

\item Sine sweeps, noise, speech, motor, and ambient noise, recorded with an 8-channel in-flight (drone) microphone array in carpeted rooms \cite{strauss2018dregon}. Motion capture data included. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{EigenScape (Green and Murphy, 2017)}

\begin{itemize}

\item Ambient noise recorded with the 32-channel EigenMike microphone array in open spaces, including beach, streer, park, and woods \cite{green2017eigenscape}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{ARTE (Weisset et al., 2019)}

\begin{itemize}

\item Sine sweeps and ambient noise, recorded with a 62-channel spherical microphone array at various indoor spaces in a university \cite{weisser2019ambisonic}. See table \ref{tab:t1} for details.

\end{itemize}

\subsection{WHISPER (Ceolini et al. 2019)}

\begin{itemize}

\item Concurrent and noisy speech recorded with 16 microphones on a table in a room with low reverberation \cite{ceolini2020evaluating}.

\end{itemize}

\subsection{MDMAD (Corey et al. 2019)}

\begin{itemize}

\item Sine sweeps, speech, and ambient noise, recorded with 8-channel table-top microphone arrays (emulating home voice assistant accessories) and 16-channel wearables on mannequins in a reverberant conference room \cite{corey2019massive}.

\end{itemize}

\subsection{METU SPARG (Olgun and Hacihabiboglu, 2019)}

\begin{itemize}

\item Sine sweeps recorded with the 32-channel EigenMike array in a classroom \cite{olgun2019metu}.

\end{itemize}

\subsection{Detmold (Amengual et al., 2020)}

\begin{itemize}

\item Sine sweeps recorded with a 6-channel spherical microphone array and an artificial head in concert halls \cite{amengual2020open}.

\end{itemize}

\subsection{MIMII (Purohit et al., 2019)}

\begin{itemize}

\item Ambient and machine sounds recorded with an 8-channel circular microphone array in a factory \cite{purohit2019mimii}.

\end{itemize}

\subsection{Hear-and-Avoid (Wijnker et al., 2019)}

\begin{itemize}

\item Overflying planes recorded with a 63-channel microphone array (horizontal board) on an airport \cite{wijnker2019hear}.

\end{itemize}

\subsection{SMARD (Nielsen et al., 2014)}

\begin{itemize}

\item Sine sweeps, speech, music, noise, and ambient noise, recorded with three diffrent microphone arrays (34 channels total) in a semi-anechoic listening room \cite{nielsen2014single}.

\end{itemize}

\subsection{Pori (Merimaa et al., 2005)}

\begin{itemize}

\item Sine sweep recordings with a tetrahedral microphone in a concert hall \cite{merimaa2005concert}.

\end{itemize}

\subsection{BUT Speech (Szoke et al., 2019)}

\begin{itemize}

\item Sine sweep and speech recordings with 13 microphones placed throughout 9 different rooms \cite{szoke2019building}.

\end{itemize}

\subsection{MMA (Swyssig et al., 2013)}

\begin{itemize}

\item Speech (WSJ) recordings with 5 microphone arrays (40 channels in total) in a meetng room and an anechoic room \cite{zwyssig2013recognition}.

\end{itemize}

\subsection{AV quadcopter (Wang et al., 2019)}

\begin{itemize}

\item Ambient and speech recordings with an 8-channel microphone array mounted on a drone in a park. Video recordings are also part of the dataset \cite{wang2019audio}.

\end{itemize}

\subsection{BIRD (Grondin et al., 2020)}

\begin{itemize}

\item 100,000 simulated multichannel room impulse responses via the image method with multiple sound sources \cite{grondin2020bird}.

\end{itemize}

\subsection{AMI (McCowan et al., 2005)}

\begin{itemize}

\item Recordings of meeting in an office environment (100 hours) with 4-ch or 8-ch microphone arrays \cite{mccowan2005ami}.

\end{itemize}

\subsection{TA2 (Duffner et al., 2012)}

\begin{itemize}

\item People in two diffrent rooms, recorded with 12 different microphones throughout the rooms while playing an online videogame. Annotations of individual's head position are included \cite{duffner2012ta2}.

\end{itemize}

\subsection{CHIME4 (Vincent et al., 2017)}

\begin{itemize}

\item WSJ sentences recorded with a 6-channel microphone array in noisy environments by multiple simultaneous talkers \cite{vincent2017analysis}.

\end{itemize}

\bibliography{references}
\bibliographystyle{plain}

\end{document}
